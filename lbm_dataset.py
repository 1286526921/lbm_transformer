import numpy as np
import warnings

# -------------------------- LBMæ ¸å¿ƒå‚æ•°ï¼ˆD2Q9ï¼‰ --------------------------
Q = 9  # ç¦»æ•£é€Ÿåº¦æ–¹å‘æ•°
# D2Q9ç¦»æ•£é€Ÿåº¦ï¼ˆ9ä¸ªæ–¹å‘ï¼Œ2ç»´ï¼‰
e = np.array([
    [0, 0], [1, 0], [0, 1], [-1, 0], [0, -1],
    [1, 1], [-1, 1], [-1, -1], [1, -1]
], dtype=np.float64)
# D2Q9æƒé‡ç³»æ•°ï¼ˆä»…åœ¨å®ˆæ’è®¡ç®—æ—¶ä½¿ç”¨ï¼‰
w = np.array([4 / 9, 1 / 9, 1 / 9, 1 / 9, 1 / 9, 1 / 36, 1 / 36, 1 / 36, 1 / 36], dtype=np.float64)

# -------------------------- å…¨å±€é…ç½®å‚æ•° --------------------------
SAMPLE_NUM = 120000  # æ€»æ ·æœ¬æ•°é‡
SAVE_PATH = "lbm_dataset_final_no_weight-range.npy"  # ä¿å­˜è·¯å¾„
RHO_RANGE = (0.5, 1.5)  # å¯†åº¦å–å€¼èŒƒå›´
PERTURB_SCALE = 0.01  # åŸºç¡€æ‰°åŠ¨å¼ºåº¦ï¼ˆæ— æƒé‡ï¼‰
HIGH_ORDER_SCALE = 0.005  # é«˜é˜¶çŸ©æ‰°åŠ¨å¼ºåº¦
MA_RANGE = (0.0, 0.3)  # é©¬èµ«æ•°èŒƒå›´ï¼ˆæ›¿æ¢åŸåˆ†å±‚ï¼Œæ”¹ä¸ºè¿ç»­èŒƒå›´ï¼‰
c_s = 1.0 / np.sqrt(3)  # D2Q9å£°é€Ÿï¼ˆå›ºå®šå€¼ï¼‰
c_s_sq = c_s ** 2  # å£°é€Ÿå¹³æ–¹ï¼ˆé¢„è®¡ç®—å‡å°‘é‡å¤è®¡ç®—ï¼‰
c_s_4 = c_s_sq ** 2  # å£°é€Ÿå››æ¬¡æ–¹ï¼ˆé¢„è®¡ç®—ï¼‰
MIN_F_EQ = 1e-8  # f_eqæœ€å°å…è®¸å€¼ï¼ˆé¿å…è´Ÿæ•°/é›¶ï¼‰
MAX_PERTURB_RATIO = 0.2  # æœ€å¤§æ‰°åŠ¨æ¯”ä¾‹ï¼ˆç›¸å¯¹äºf_eqï¼Œä¿è¯ç‰©ç†ä¸€è‡´æ€§ï¼‰


# -------------------------- å¹³è¡¡æ€è®¡ç®—ï¼ˆæ— æƒé‡+è´Ÿæ•°æ£€æµ‹+éè´Ÿä¿®æ­£ï¼‰ --------------------------
def compute_f_eq(rho, u, check_negative=True):
    """
    è®¡ç®—D2Q9æ— æƒé‡å¹³è¡¡æ€åˆ†å¸ƒï¼Œæ–°å¢è´Ÿæ•°æ£€æµ‹å’Œéè´Ÿä¿®æ­£
    :param rho: å¯†åº¦æ ‡é‡ (float64)
    :param u: é€Ÿåº¦å‘é‡ (2,) (float64)
    :param check_negative: æ˜¯å¦æ£€æµ‹å¹¶ä¿®æ­£è´Ÿæ•°
    :return: f_eq: æ— æƒé‡å¹³è¡¡æ€åˆ†å¸ƒ (9,) (float64)
    """
    f_eq = np.zeros(Q, dtype=np.float64)
    u_sq = np.dot(u, u)  # é€Ÿåº¦æ¨¡é•¿å¹³æ–¹
    for i in range(Q):
        e_i = e[i]
        eu = np.dot(e_i, u)  # é€Ÿåº¦æ–¹å‘ä¸å®è§‚é€Ÿåº¦çš„ç‚¹ç§¯
        e_sq = np.dot(e_i, e_i)  # ç¦»æ•£é€Ÿåº¦æ¨¡é•¿å¹³æ–¹

        # D2Q9æ— æƒé‡å¹³è¡¡æ€æ ¸å¿ƒå…¬å¼
        f_eq[i] = rho * (
                1 + eu / c_s_sq +
                (eu ** 2) / (2 * c_s_4) -
                u_sq / (2 * c_s_sq)  # ä¿®æ­£åŸå…¬å¼é”™è¯¯ï¼šåŸe_sqâ†’u_sqï¼ˆD2Q9æ ‡å‡†å…¬å¼ï¼‰
        )

    # 1. æ£€æµ‹è´Ÿæ•°æƒ…å†µ
    negative_mask = f_eq < 0
    neg_count = np.sum(negative_mask)
    if neg_count > 0 and check_negative:
        warnings.warn(f"æ£€æµ‹åˆ°{neg_count}ä¸ªf_eqè´Ÿæ•°ï¼rho={rho:.4f}, u={u}, f_eq={f_eq}")
        # 2. éè´Ÿä¿®æ­£ï¼ˆä¿ç•™ç›¸å¯¹åˆ†å¸ƒï¼Œä¿è¯å®ˆæ’ï¼‰
        f_eq = np.maximum(f_eq, MIN_F_EQ)
        # ä¿®æ­£åé‡æ–°å½’ä¸€åŒ–ï¼ˆä¿è¯å¯†åº¦å®ˆæ’ï¼‰
        rho_calc = np.sum(w * f_eq)
        f_eq = f_eq * rho / rho_calc

    return f_eq


# -------------------------- ç‰©ç†ä¸€è‡´æ€§æ‰°åŠ¨ç”Ÿæˆï¼ˆæ›¿ä»£åŸéšæœºæ‰°åŠ¨ï¼‰ --------------------------
def generate_physically_consistent_perturbation(f_eq):
    """
    ç”Ÿæˆç¬¦åˆæµä½“ç‰©ç†çš„æ‰°åŠ¨ï¼š
    1. æ‰°åŠ¨å¹…åº¦ä¸f_eqæ­£ç›¸å…³ï¼ˆé¿å…å°f_eqè¢«è¿‡åº¦æ‰°åŠ¨ï¼‰
    2. é™åˆ¶æœ€å¤§æ‰°åŠ¨æ¯”ä¾‹ï¼ˆé¿å…éç‰©ç†çš„å¤§æ‰°åŠ¨ï¼‰
    3. åˆå§‹æ‰°åŠ¨ä¿è¯éè´Ÿæ€§
    :param f_eq: å¹³è¡¡æ€åˆ†å¸ƒ (9,)
    :return: perturbation: ç‰©ç†ä¸€è‡´çš„åˆå§‹æ‰°åŠ¨ (9,)
    """
    # 1. ç”Ÿæˆä¸f_eqæˆæ¯”ä¾‹çš„æ‰°åŠ¨å¹…åº¦ï¼ˆè‡ªé€‚åº”ï¼‰
    perturb_amplitude = PERTURB_SCALE * f_eq
    # 2. é™åˆ¶æœ€å¤§æ‰°åŠ¨æ¯”ä¾‹ï¼ˆé¿å…è¿‡åº¦æ‰°åŠ¨ï¼‰
    max_perturb = MAX_PERTURB_RATIO * f_eq
    perturb_amplitude = np.minimum(perturb_amplitude, max_perturb)

    # 3. ç”Ÿæˆæˆªæ–­æ­£æ€åˆ†å¸ƒæ‰°åŠ¨ï¼ˆ-1~1ä¹‹é—´ï¼Œé¿å…æç«¯å€¼ï¼‰
    perturbation = np.random.normal(0, 1, Q)
    perturbation = np.clip(perturbation, -1, 1)  # æˆªæ–­åˆ°åˆç†èŒƒå›´
    perturbation = perturbation * perturb_amplitude

    # 4. é¢„ä¿®æ­£ï¼šä¿è¯æ‰°åŠ¨åf_non_eqéè´Ÿï¼ˆç‰©ç†çº¦æŸï¼‰
    min_allowed_perturb = MIN_F_EQ - f_eq
    perturbation = np.clip(perturbation, min_allowed_perturb, max_perturb)

    return perturbation


# -------------------------- å®ˆæ’æ‰°åŠ¨ä¿®æ­£ï¼ˆæ˜¾å¼è¡¥æƒé‡ï¼‰ --------------------------
def correct_perturbation(perturbation, f_eq):
    """
    ä¿®æ­£æ‰°åŠ¨ä»¥ä¿è¯å¯†åº¦/åŠ¨é‡å®ˆæ’ï¼Œæ–°å¢ç‰©ç†çº¦æŸæ£€æŸ¥
    :param perturbation: åˆå§‹æ— æƒé‡æ‰°åŠ¨ (9,)
    :param f_eq: å¹³è¡¡æ€åˆ†å¸ƒï¼ˆç”¨äºéè´Ÿæ€§éªŒè¯ï¼‰
    :return: corrected_pert: å®ˆæ’ä¿®æ­£åçš„æ‰°åŠ¨ (9,)
    """
    # 1. è®¡ç®—æ‰°åŠ¨å¯¼è‡´çš„å®ˆæ’åå·®
    delta_rho = np.sum(w * perturbation)  # å¯†åº¦åå·® = Î£(wÂ·æ‰°åŠ¨)
    delta_mom = np.sum(w[:, np.newaxis] * perturbation[:, np.newaxis] * e, axis=0)  # åŠ¨é‡åå·®

    # 2. æ„é€ å®ˆæ’çº¦æŸçŸ©é˜µ
    constraint_matrix = np.vstack([
        w,  # å¯†åº¦çº¦æŸè¡Œ
        w * e[:, 0],  # xåŠ¨é‡çº¦æŸè¡Œ
        w * e[:, 1]  # yåŠ¨é‡çº¦æŸè¡Œ
    ])

    # 3. ä¼ªé€†æ±‚è§£ä¿®æ­£ç³»æ•°
    constraint_pinv = np.linalg.pinv(constraint_matrix)
    target_bias = np.array([delta_rho, delta_mom[0], delta_mom[1]], dtype=np.float64)
    correction_coeff = constraint_pinv @ target_bias

    # 4. åº”ç”¨ä¿®æ­£
    corrected_pert = perturbation - correction_coeff

    # 5. éªŒè¯ä¿®æ­£åéè´Ÿæ€§ï¼ˆç‰©ç†çº¦æŸï¼‰
    f_non_eq_temp = f_eq + corrected_pert
    if np.any(f_non_eq_temp < MIN_F_EQ):
        # äºŒæ¬¡ä¿®æ­£ï¼šè°ƒæ•´æ‰°åŠ¨å¹…åº¦ä»¥ä¿è¯éè´Ÿ
        scale_factor = 0.9
        corrected_pert = corrected_pert * scale_factor
        f_non_eq_temp = f_eq + corrected_pert
        if np.any(f_non_eq_temp < MIN_F_EQ):
            warnings.warn("ä¿®æ­£åä»å­˜åœ¨éè´Ÿæ€§é—®é¢˜ï¼Œè¿›ä¸€æ­¥ç¼©å°æ‰°åŠ¨å¹…åº¦")
            corrected_pert = corrected_pert * 0.5

    # éªŒè¯ä¿®æ­£æ•ˆæœ
    delta_rho_new = np.sum(w * corrected_pert)
    delta_mom_new = np.sum(w[:, np.newaxis] * corrected_pert[:, np.newaxis] * e, axis=0)
    assert np.isclose(delta_rho_new, 0, atol=1e-10), f"å¯†åº¦ä¿®æ­£å¤±è´¥: {delta_rho_new:.2e}"
    assert np.linalg.norm(delta_mom_new) < 1e-10, f"åŠ¨é‡ä¿®æ­£å¤±è´¥: {delta_mom_new}"

    return corrected_pert


# -------------------------- é«˜é˜¶çŸ©æ‰°åŠ¨ï¼ˆä¸ç ´åå®ˆæ’ï¼‰ --------------------------
def add_high_order_perturbation(perturbation, f_eq):
    """
    æ·»åŠ åŠ¨èƒ½çŸ©é«˜é˜¶æ‰°åŠ¨ï¼Œæ–°å¢ç‰©ç†çº¦æŸ
    :param perturbation: å®ˆæ’ä¿®æ­£åçš„æ‰°åŠ¨ (9,)
    :param f_eq: å¹³è¡¡æ€åˆ†å¸ƒï¼ˆç”¨äºéè´Ÿæ€§éªŒè¯ï¼‰
    :return: final_pert: å«é«˜é˜¶çŸ©åå·®çš„æ‰°åŠ¨ (9,)
    """
    # 1. æ„é€ æ­£äº¤äºå®ˆæ’çº¦æŸçš„é«˜é˜¶çŸ©åŸº
    e_mag_sq = np.sum(e * e, axis=1)  # ç¦»æ•£é€Ÿåº¦æ¨¡é•¿å¹³æ–¹ (9,)
    high_order_basis = w * (e_mag_sq - np.mean(e_mag_sq))

    # æ­£äº¤åŒ–ï¼šç§»é™¤ä¸å®ˆæ’åŸºçš„æŠ•å½±
    high_order_basis = high_order_basis - np.dot(high_order_basis, w) * w / np.dot(w, w)
    wx = w * e[:, 0]
    high_order_basis = high_order_basis - np.dot(high_order_basis, wx) * wx / np.dot(wx, wx)
    wy = w * e[:, 1]
    high_order_basis = high_order_basis - np.dot(high_order_basis, wy) * wy / np.dot(wy, wy)

    # å½’ä¸€åŒ–åŸºå‘é‡
    basis_norm = np.linalg.norm(high_order_basis)
    if basis_norm > 1e-10:
        high_order_basis = high_order_basis / basis_norm

    # 2. ç”Ÿæˆéšæœºé«˜é˜¶çŸ©æ‰°åŠ¨ï¼ˆé™åˆ¶å¹…åº¦ï¼‰
    high_order_pert = HIGH_ORDER_SCALE * np.random.normal(0, 1) * high_order_basis

    # 3. éªŒè¯ä¸ç ´åå®ˆæ’
    assert np.isclose(np.sum(w * high_order_pert), 0, atol=1e-10), "é«˜é˜¶çŸ©æ‰°åŠ¨ç ´åå¯†åº¦å®ˆæ’"
    assert np.linalg.norm(np.sum(w[:, np.newaxis] * high_order_pert[:, np.newaxis] * e, axis=0)) < 1e-10, \
        "é«˜é˜¶çŸ©æ‰°åŠ¨ç ´ååŠ¨é‡å®ˆæ’"

    # 4. å åŠ å‰éªŒè¯éè´Ÿæ€§
    temp_pert = perturbation + high_order_pert
    f_non_eq_temp = f_eq + temp_pert
    if np.any(f_non_eq_temp < MIN_F_EQ):
        # ç¼©å°é«˜é˜¶æ‰°åŠ¨å¹…åº¦
        high_order_pert = high_order_pert * 0.5

    # 5. å åŠ é«˜é˜¶çŸ©æ‰°åŠ¨
    final_pert = perturbation + high_order_pert

    return final_pert


# -------------------------- æ•°æ®é›†ç”Ÿæˆä¸»å‡½æ•° --------------------------
def generate_enhanced_dataset():
    """
    ç”Ÿæˆæ— æƒé‡å¹³è¡¡æ€+æ˜¾å¼è¡¥æƒé‡å®ˆæ’çš„LBMæ•°æ®é›†ï¼ˆé©¬èµ«æ•°èŒƒå›´é‡‡æ ·+é«˜é˜¶çŸ©+ç‰©ç†çº¦æŸï¼‰
    """
    dataset = []
    # ç»Ÿè®¡ä¿¡æ¯
    stats = {
        "mach_numbers": [],
        "rho_values": [],
        "density_errors": [],
        "momentum_errors": [],
        "high_order_biases": [],
        "negative_f_eq_count": 0,  # f_eqè´Ÿæ•°æ¬¡æ•°
        "non_negative_correction_count": 0  # éè´Ÿä¿®æ­£æ¬¡æ•°
    }

    print(f"\n=== æŒ‰é©¬èµ«æ•°èŒƒå›´ [{MA_RANGE[0]}, {MA_RANGE[1]}] ç”Ÿæˆ {SAMPLE_NUM} ä¸ªæ ·æœ¬ ===")

    # æŒ‰èŒƒå›´ç”Ÿæˆæ‰€æœ‰æ ·æœ¬ï¼ˆæ›¿æ¢åŸåˆ†å±‚é€»è¾‘ï¼‰
    for sample_idx in range(SAMPLE_NUM):
        if sample_idx % 5000 == 0:  # è°ƒæ•´è¿›åº¦æ‰“å°é¢‘ç‡ï¼ˆé¿å…è¿‡å¤šè¾“å‡ºï¼‰
            print(f"  è¿›åº¦: {sample_idx}/{SAMPLE_NUM}")

        # ä»æŒ‡å®šèŒƒå›´éšæœºé‡‡æ ·é©¬èµ«æ•°
        ma_actual = np.random.uniform(*MA_RANGE)
        max_u_mag = ma_actual * c_s  # é€Ÿåº¦å¹…å€¼ï¼ˆåŸºäºé‡‡æ ·çš„é©¬èµ«æ•°ï¼‰

        # é‡‡æ ·ç‰©ç†é‡
        rho = np.random.uniform(*RHO_RANGE)
        theta = np.random.uniform(0, 2 * np.pi)  # éšæœºé€Ÿåº¦æ–¹å‘
        u = np.array([
            max_u_mag * np.cos(theta),
            max_u_mag * np.sin(theta)
        ], dtype=np.float64)

        # è®¡ç®—æ— æƒé‡å¹³è¡¡æ€ï¼ˆå¸¦è´Ÿæ•°æ£€æµ‹ï¼‰
        f_eq = compute_f_eq(rho, u)

        # ç»Ÿè®¡f_eqè´Ÿæ•°æƒ…å†µ
        if np.sum(f_eq < 0) > 0:
            stats["negative_f_eq_count"] += 1

        # ç”Ÿæˆç‰©ç†ä¸€è‡´æ€§åˆå§‹æ‰°åŠ¨
        perturbation = generate_physically_consistent_perturbation(f_eq)

        # ç¬¬ä¸€æ­¥ä¿®æ­£ï¼šä¿è¯å®ˆæ’
        perturb_corrected = correct_perturbation(perturbation, f_eq)

        # ç¬¬äºŒæ­¥æ‰©å±•ï¼šæ·»åŠ é«˜é˜¶çŸ©æ‰°åŠ¨
        perturb_final = add_high_order_perturbation(perturb_corrected, f_eq)

        # ç”Ÿæˆæœ€ç»ˆæ— æƒé‡éå¹³è¡¡æ€åˆ†å¸ƒ
        f_non_eq = f_eq + perturb_final

        # æœ€ç»ˆéè´Ÿæ€§æ£€æŸ¥
        if np.any(f_non_eq < MIN_F_EQ):
            stats["non_negative_correction_count"] += 1
            f_non_eq = np.maximum(f_non_eq, MIN_F_EQ)
            # é‡æ–°ä¿®æ­£å®ˆæ’ï¼ˆä¿è¯ç‰©ç†çº¦æŸï¼‰
            rho_calc = np.sum(w * f_non_eq)
            f_non_eq = f_non_eq * rho / rho_calc

        # éªŒè¯å®ˆæ’æ€§
        rho_calc = np.sum(w * f_non_eq)
        rho_true = np.sum(w * f_eq)
        density_error = abs(rho_calc - rho_true)

        mom_calc = np.sum(w[:, np.newaxis] * f_non_eq[:, np.newaxis] * e, axis=0)
        mom_true = np.sum(w[:, np.newaxis] * f_eq[:, np.newaxis] * e, axis=0)
        momentum_error = np.linalg.norm(mom_calc - mom_true)

        # ç»Ÿè®¡é«˜é˜¶çŸ©åå·®
        e_mag_sq = np.sum(e * e, axis=1)
        M_kin_eq = np.sum(w * f_eq * e_mag_sq)
        M_kin_non_eq = np.sum(w * f_non_eq * e_mag_sq)
        high_order_bias = abs(M_kin_non_eq - M_kin_eq)

        # è®°å½•ç»Ÿè®¡ä¿¡æ¯
        stats["mach_numbers"].append(ma_actual)
        stats["rho_values"].append(rho)
        stats["density_errors"].append(density_error)
        stats["momentum_errors"].append(momentum_error)
        stats["high_order_biases"].append(high_order_bias)

        # æ·»åŠ åˆ°æ•°æ®é›†
        dataset.append({
            "f_non_eq": f_non_eq,
            "f_eq": f_eq,
            "rho": rho,
            "u": u,
            "mach_number": ma_actual,
            "density_error": density_error,
            "momentum_error": momentum_error,
            "high_order_bias": high_order_bias
        })

    # ä¿å­˜æ•°æ®é›†
    np.save(SAVE_PATH, dataset)

    # è¾“å‡ºç»Ÿè®¡æŠ¥å‘Š
    print("\n=== æ•°æ®é›†ç”Ÿæˆå®Œæˆï¼ˆç‰©ç†çº¦æŸå¢å¼ºç‰ˆï¼‰ ===")
    print(f"ğŸ“Š æ ¸å¿ƒç»Ÿè®¡ï¼š")
    print(f"  æ€»æ ·æœ¬æ•°: {len(dataset)}")
    print(f"  é©¬èµ«æ•°èŒƒå›´: {np.min(stats['mach_numbers']):.3f} ~ {np.max(stats['mach_numbers']):.3f}")
    print(f"  å¯†åº¦èŒƒå›´: {np.min(stats['rho_values']):.3f} ~ {np.max(stats['rho_values']):.3f}")
    print(f"  å¹³å‡å¯†åº¦å®ˆæ’è¯¯å·®: {np.mean(stats['density_errors']):.2e} (æœ€å¤§: {np.max(stats['density_errors']):.2e})")
    print(f"  å¹³å‡åŠ¨é‡å®ˆæ’è¯¯å·®: {np.mean(stats['momentum_errors']):.2e} (æœ€å¤§: {np.max(stats['momentum_errors']):.2e})")
    print(
        f"  å¹³å‡é«˜é˜¶çŸ©åå·®: {np.mean(stats['high_order_biases']):.2e} (æœ€å¤§: {np.max(stats['high_order_biases']):.2e})")
    print(f"  ğŸ” ç‰©ç†çº¦æŸç»Ÿè®¡ï¼š")
    print(f"    f_eqè´Ÿæ•°å‡ºç°æ¬¡æ•°: {stats['negative_f_eq_count']}")
    print(f"    éè´Ÿæ€§ä¿®æ­£æ¬¡æ•°: {stats['non_negative_correction_count']}")
    print(f"ğŸ’¾ ä¿å­˜è·¯å¾„: {SAVE_PATH}")

    # éªŒè¯åŠ è½½
    loaded_dataset = np.load(SAVE_PATH, allow_pickle=True)
    print(loaded_dataset[0]['f_non_eq'].dtype)
    print(f"\nâœ… åŠ è½½éªŒè¯ï¼š")
    print(f"  åŠ è½½æ ·æœ¬æ•°: {len(loaded_dataset)}")
    print(f"  ç¬¬ä¸€ä¸ªæ ·æœ¬é©¬èµ«æ•°: {loaded_dataset[0]['mach_number']:.3f}")
    print(f"  ç¬¬ä¸€ä¸ªæ ·æœ¬å¯†åº¦è¯¯å·®: {loaded_dataset[0]['density_error']:.2e}")
    print(f"  ç¬¬ä¸€ä¸ªæ ·æœ¬f_eqæœ€å°å€¼: {np.min(loaded_dataset[0]['f_eq']):.4e}")
    print(f"  ç¬¬ä¸€ä¸ªæ ·æœ¬f_non_eqæœ€å°å€¼: {np.min(loaded_dataset[0]['f_non_eq']):.4e}")

    return dataset


# -------------------------- æ‰§è¡Œå…¥å£ --------------------------
if __name__ == "__main__":
    # ç”Ÿæˆæœ€ç»ˆç‰ˆæ•°æ®é›†
    generate_enhanced_dataset()